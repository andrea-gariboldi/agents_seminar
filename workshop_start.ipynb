{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4daf74a1",
   "metadata": {},
   "source": [
    "# Developing LLM agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install() #get conda for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone https://github.com/andrea-gariboldi/agents_seminar #clone seminar repository\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q pydantic-ai==1.7.0 pandas==2.3.1 scikit-learn==1.7.1 #install necessary packages\n",
    "\n",
    "sys.path.append('/content/agents_seminar') #add repo to path for main script\n",
    "\n",
    "!conda env create -f /content/agents_seminar/env.yaml #create conda env for the agent\n",
    "\n",
    "!curl -fsSL https://ollama.com/install.sh | sh #install Ollama\n",
    "\n",
    "!nohup ollama serve > ollama.log 2>&1 &\n",
    "!sleep 5 #start Ollama and make it listen\n",
    "\n",
    "!!ollama pull gpt-oss:20b #pull llm model\n",
    "\n",
    "os.chdir('/content/agents_seminar') #set current working dir inside the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "import os\n",
    "\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "from pydantic_ai.providers.ollama import OllamaProvider\n",
    "\n",
    "from utils.agent_utils import run_agent\n",
    "from utils.workspace_utils import cleanup_workspace\n",
    "from eval.evaluate_result import evaluate_clustering\n",
    "\n",
    "workspace_dir = f\"{os.getcwd()}/agents_workspace/\" # define where the agent will work\n",
    "\n",
    "cleanup_workspace(workspace_dir=workspace_dir) # delete files produced by previous runs\n",
    "\n",
    "ollama_model = OpenAIChatModel( # LLM model definition, will be used by the agent\n",
    "    model_name='gpt-oss:20b', # model downloaded locally with Ollama in previous cell\n",
    "    provider=OllamaProvider(base_url='http://localhost:11434/v1'), # define wheere Ollama is listening\n",
    ")\n",
    "\n",
    "agent = Agent( # define the agent\n",
    "    ollama_model,\n",
    "    system_prompt=\"You are an expert agent with scripting skills. Use the tools available to answer the user's requests.\"\n",
    ") # system prompt guides the agent behavior\n",
    "\n",
    "user_prompt = f\"\"\"Your final deliverable is to cluster a dataset. The original dataset is in the directory: {workspace_dir}data/. Take decisions on how to cluster based on the data provided.\n",
    "            You should provide a python script that takes two commnad line arguments: --input for the input dataset path and --output for the output submission file path.\n",
    "            The script should read the dataset from the input path, perform clustering, and save a submission file that contains the original columns,\n",
    "            plus a new column 'cluster_id' indicating the cluster assignment for each row.\n",
    "            Save the script as cluster.py in the current working directory ({workspace_dir}).\n",
    "            \"\"\"\n",
    "#user prompt defines the tasks and the deliverables expected from the agent\n",
    "\n",
    "async def main():\n",
    "    await run_agent( #this runs the agent loop\n",
    "        agent = agent,\n",
    "        user_prompt=user_prompt,\n",
    "        max_steps=10 # max 10 agent steps/actions - prevent infinite loops\n",
    "    )\n",
    "\n",
    "    # at this point, the agent has finished its run and we need to evaluate the produced clustering script\n",
    "    evaluate_clustering(script_path=f\"{os.getcwd()}/agents_workspace/cluster.py\") #fixed programmatic evaluation after agent run\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
